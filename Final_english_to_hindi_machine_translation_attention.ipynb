{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Final_english_to_hindi_machine_translation_attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQkhjM4-baeI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0e80e21d-516b-4edf-faeb-d35ed137552c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tvd3_bfH3st",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f3bd5bca-86de-4286-e11d-8c79c3de7ce9"
      },
      "source": [
        "%cd /content/drive/My Drive/Dataset/Better\n",
        "!git clone  https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Dataset/Better\n",
            "fatal: destination path 'indic_nlp_resources' already exists and is not an empty directory.\n",
            "fatal: destination path 'indic_nlp_library' already exists and is not an empty directory.\n",
            "clean_english-hindi-both.pkl   English_large_modified.txt  indic_nlp_resources\n",
            "clean_english-hindi.pkl        Fonts\t\t\t   saved_model_weights\n",
            "clean_english-hindi-test.pkl   Hindi_large_modified.txt    training_checkpoints\n",
            "clean_english-hindi-train.pkl  indic_nlp_library\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHxktsMmJvo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "# The path to the local git repo for Indic NLP library\n",
        "INDIC_NLP_LIB_HOME=r\"/content/drive/My Drive/Dataset/Better/indic_nlp_library\"\n",
        "\n",
        "# The path to the local git repo for Indic NLP Resources\n",
        "INDIC_NLP_RESOURCES=r\"/content/drive/My Drive/Dataset/Better/indic_nlp_resources\"\n",
        "\n",
        "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))\n",
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
        "from indicnlp import loader\n",
        "loader.load()\n",
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLqvqvOnaUiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import os\n",
        "import string\n",
        "import numpy as np\n",
        "from numpy.random import rand, shuffle\n",
        "import pandas as pd\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import matplotlib.font_manager as fm\n",
        "%matplotlib inline\n",
        "import re\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "import unicodedata\n",
        "from pickle import dump, load\n",
        "import io\n",
        "import time\n",
        "import warnings\n",
        "import sys\n",
        "from unicodedata import normalize\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEiZA-R_aUiZ",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess English and Hindi sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh3iE8ccFO8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save a list of clean sentences to file\n",
        "def save_clean_data(sentences, filename):\n",
        "    dump(sentences, open(filename, 'wb'), protocol=4)\n",
        "    print('Saved: %s' % filename)\n",
        "\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "    return load(open(filename, 'rb'))\n",
        "\n",
        "class LanguageIndex():\n",
        "  def __init__(self, lang):\n",
        "    self.lang = lang\n",
        "    self.word2idx = {}\n",
        "    self.idx2word = {}\n",
        "    self.vocab = set()\n",
        "    \n",
        "    self.create_index()\n",
        "    \n",
        "  def create_index(self):\n",
        "    for phrase in self.lang:\n",
        "      self.vocab.update(phrase.split(' '))\n",
        "    \n",
        "    self.vocab = sorted(self.vocab)\n",
        "    \n",
        "    self.word2idx['<pad>'] = 0\n",
        "    for index, word in enumerate(self.vocab):\n",
        "      self.word2idx[word] = index + 1\n",
        "    \n",
        "    for word, index in self.word2idx.items():\n",
        "      self.idx2word[index] = word\n",
        "\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS8qm-j6FVy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_doc(filename):\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "def to_pairs(english_text, hindi_text):\n",
        "    english_lines = english_text.strip().split('\\n')\n",
        "    hindi_lines = hindi_text.strip().split('\\n')\n",
        "    pairs = []\n",
        "    for i in range(len(hindi_lines)):\n",
        "        pairs.append([])\n",
        "        pairs[i].append(pre_process_english_sentence(english_lines[i]))\n",
        "        pairs[i].append(pre_process_hindi_sentence(hindi_lines[i]))\n",
        "    return pairs\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.replace(u',',' ')\n",
        "    text = text.replace(u'\"','')\n",
        "    text = text.replace(u'\"','')\n",
        "    text = text.replace(u\"‘‘\",'')\n",
        "    text = text.replace(u\"’’\",'')\n",
        "    text = text.replace(u\"''\",'')\n",
        "    text = text.replace(u\"।\",' ')\n",
        "    text=text.replace(u',',' ')\n",
        "    text=text.replace(u'\"',' ')\n",
        "    text=text.replace(u'(',' ')\n",
        "    text=text.replace(u')',' ')\n",
        "    text=text.replace(u'\"',' ')\n",
        "    text=text.replace(u':',' ')\n",
        "    text=text.replace(u\"'\",'')\n",
        "    text=text.replace(u\"‘‘\",' ')\n",
        "    text=text.replace(u\"’’\",' ')\n",
        "    text=text.replace(u\"''\",' ')\n",
        "    text=text.replace(u\".\",' ')\n",
        "    text=text.replace(u\"-\",' ')\n",
        "    text=text.replace(u\"।\",' ')\n",
        "    text=text.replace(u\"?\",' ')\n",
        "    text=text.replace(u\"\\\\\",' ')\n",
        "    text=text.replace(u\"_\",' ')\n",
        "    text=text.replace(\"'\", \"\")\n",
        "    text=text.replace('\"', \"\")\n",
        "    text= re.sub(\"'\", '', text)\n",
        "    text= re.sub(\"’\", '', text)\n",
        "    text=re.sub('[0-9+\\-*/.%]', ' ', text)\n",
        "    text=text.strip()\n",
        "    text=re.sub(' +', ' ',text)\n",
        "    exclude = set(string.punctuation)\n",
        "    text= ''.join(ch for ch in text if ch not in exclude)\n",
        "    return text\n",
        "\n",
        "def pre_process_english_sentence(line):\n",
        "    line = line.lower()\n",
        "    line = clean_text(line)\n",
        "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "    line = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "    line = line.decode('UTF-8')\n",
        "    line = line.split()\n",
        "    line = [re_print.sub('', w) for w in line]\n",
        "    line = [word for word in line if word.isalpha()]\n",
        "    line = ' '.join(line)\n",
        "    line = '<start> '+ line + ' <end>'\n",
        "    return line\n",
        "\n",
        "def pre_process_hindi_sentence(line):\n",
        "    line=re.sub('[a-zA-Z]', '', line)\n",
        "    line = clean_text(line)\n",
        "    remove_nuktas = False\n",
        "    factory = IndicNormalizerFactory()\n",
        "    normalizer = factory.get_normalizer(\"hi\")\n",
        "    line = normalizer.normalize(line)\n",
        "    tokens = list()\n",
        "    for t in indic_tokenize.trivial_tokenize(line):\n",
        "        tokens.append(t)\n",
        "    line = tokens\n",
        "    line = [word for word in line if not re.search(r'\\d', word)]\n",
        "    line = ' '.join(line)\n",
        "    # line = ItransTransliterator.to_itrans(line, 'hi')\n",
        "    line = '<start> '+ line + ' <end>'\n",
        "    return (line)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNfz8hpDCGgc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffcc8d3f-62c9-4756-920b-60644105cf1b"
      },
      "source": [
        "english_text = load_doc('English_large_modified.txt')\n",
        "hindi_text = load_doc('Hindi_large_modified.txt')\n",
        "pairs = to_pairs(english_text, hindi_text)\n",
        "clean_pairs = np.array(pairs)\n",
        "save_clean_data(clean_pairs, 'clean_english-hindi.pkl')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: clean_english-hindi.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IARoqGMUSIDR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4ecf9b07-25b1-4e8f-93ea-8a64b812c9dc"
      },
      "source": [
        "clean_pairs[2363]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['<start> i like the blue one how much does it cost <end>',\n",
              "       '<start> मुझे नीली वाली पसंद है कितने की है <end>'], dtype='<U112')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlqxBmzrFcQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_dataset(dataset_path, dataset_size=None):\n",
        "  raw_dataset = load_clean_sentences(dataset_path)\n",
        "  if dataset_size==None:\n",
        "    dataset_size = len(raw_dataset)\n",
        "  n_sentences = dataset_size\n",
        "  n_train = (int)(n_sentences*80/100)\n",
        "  dataset = raw_dataset[:n_sentences, :]\n",
        "\n",
        "  train, test = dataset[:n_train], dataset[n_train:]\n",
        "\n",
        "  save_clean_data(dataset, 'clean_english-hindi-both.pkl')\n",
        "  save_clean_data(train, 'clean_english-hindi-train.pkl')\n",
        "  save_clean_data(test, 'clean_english-hindi-test.pkl')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaB2KPXinBVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8daadff7-1783-4edc-dc8e-259f86481056"
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "prepare_dataset('clean_english-hindi.pkl', 150000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: clean_english-hindi-both.pkl\n",
            "Saved: clean_english-hindi-train.pkl\n",
            "Saved: clean_english-hindi-test.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBE6X265FjjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = load_clean_sentences('clean_english-hindi-both.pkl')\n",
        "train = load_clean_sentences('clean_english-hindi-train.pkl')\n",
        "test = load_clean_sentences('clean_english-hindi-test.pkl')\n",
        "\n",
        "shuffle(dataset)\n",
        "shuffle(train)\n",
        "shuffle(test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKWAuajfFuSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(pairs):  \n",
        "    inp_lang = LanguageIndex(en for en, hi in pairs)\n",
        "    targ_lang = LanguageIndex(hi for en, hi in pairs)\n",
        "    input_tensor = [[inp_lang.word2idx[s] for s in en.split(' ')] for en, hi in pairs]\n",
        "    target_tensor = [[targ_lang.word2idx[s] for s in hi.split(' ')] for en, hi in pairs]\n",
        "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "    return inp_lang, targ_lang, max_length_inp, max_length_tar\n",
        "\n",
        "inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset(dataset)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_yDzi_XTs6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_tensor(pairs, max_length_inp, max_length_tar, inp_lang, targ_lang):\n",
        "    input_tensor_x = [[inp_lang.word2idx[s] for s in en.split(' ')] for en, hi in pairs]\n",
        "    target_tensor_y = [[targ_lang.word2idx[s] for s in hi.split(' ')] for en, hi in pairs]\n",
        "    input_tensor_x = tf.keras.preprocessing.sequence.pad_sequences(input_tensor_x, maxlen=max_length_inp, padding='post')\n",
        "    target_tensor_y = tf.keras.preprocessing.sequence.pad_sequences(target_tensor_y, maxlen=max_length_tar, padding='post')\n",
        "    return input_tensor_x, target_tensor_y\n",
        "\n",
        "input_tensor_train, target_tensor_train = train_tensor(train, max_length_inp, max_length_targ, inp_lang, targ_lang)\n",
        "input_tensor_val, target_tensor_val = train_tensor(test, max_length_inp, max_length_targ, inp_lang, targ_lang)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJwnGMVSciZ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ae74f5f-8a97-4f84-b23d-44a2133ceb40"
      },
      "source": [
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120000, 120000, 30000, 30000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDcFs1vbW7gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.idx2word[t]))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLpXTFNJW_y-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "efdfee8e-57ab-462f-c7fe-60681b5223ae"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[7])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[7])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "3 ----> <start>\n",
            "333 ----> accordingly\n",
            "21393 ----> it\n",
            "47031 ----> was\n",
            "29324 ----> now\n",
            "10629 ----> decided\n",
            "43828 ----> to\n",
            "38580 ----> send\n",
            "26327 ----> me\n",
            "43828 ----> to\n",
            "6362 ----> calcutta\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "2 ----> <start>\n",
            "7857 ----> उसी\n",
            "30386 ----> निश्चय\n",
            "13065 ----> के\n",
            "45489 ----> मुताबिक\n",
            "46165 ----> मेरा\n",
            "10992 ----> कलकत्ता\n",
            "21147 ----> जाना\n",
            "20742 ----> जल्दी\n",
            "62868 ----> ही\n",
            "25055 ----> तय\n",
            "32934 ----> पा\n",
            "15971 ----> गया\n",
            "1 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKpQ4dZjaUjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 128\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 64\n",
        "units = 128\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRIsfSBKaUjP",
        "colab_type": "text"
      },
      "source": [
        "## Encoder Decoder with Attention Model\n",
        "\n",
        "> Encoder Decoder with Attention model is a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. It uses a multilayered Gated Recurrent Unit (GRU) to map the input sequence to a vector of a fixed dimensionality, and then another deep GRU to decode the target sequence from the vector.\n",
        "<img src=\"https://www.researchgate.net/profile/Vlad_Zhukov2/publication/321210603/figure/fig1/AS:642862530191361@1530281779831/An-example-of-sequence-to-sequence-model-with-attention-Calculation-of-cross-entropy.png\" width=\"800\" alt=\"attention mechanism\">\n",
        "\n",
        "> A sequence to sequence model has two parts – an encoder and a decoder. Both the parts are practically two different neural network models combined into one giant network. the task of an encoder network is to understand the input sequence, and create a smaller dimensional representation of it. This representation is then forwarded to a decoder network which generates a sequence of its own that represents the output. The input is put through an encoder model which gives us the encoder output. Here, each input words is assigned a weight by the attention mechanism which is then used by the decoder to predict the next word in the sentence. We use Bahdanau attention for the encoder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta8l87hEaUjQ",
        "colab_type": "text"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lJFcwexaUjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.gru_h1 = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    x = self.gru_h1(x, initial_state = hidden)\n",
        "    output, state = self.gru(x)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "969tfHC4aUjY",
        "colab_type": "text"
      },
      "source": [
        "### Attention Mechanism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NkFiDjiaUjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y0TK1yYaUjf",
        "colab_type": "text"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gZGtSPJaUjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.gru_h1 = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "    x = self.embedding(x)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "    x = self.gru_h1(x)\n",
        "    output, state = self.gru(x)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "    x = self.fc(output)\n",
        "    return x, state, attention_weights\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYltzcsontDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "320K-2_bqXu-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "d2c154dd-f5c9-476a-8c40-b210c46de976"
      },
      "source": [
        "print(encoder.summary())\n",
        "print(decoder.summary())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      multiple                  3085376   \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  multiple                  99072     \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  multiple                  74496     \n",
            "=================================================================\n",
            "Total params: 3,258,944\n",
            "Trainable params: 3,258,944\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"decoder_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      multiple                  4074560   \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  multiple                  99072     \n",
            "_________________________________________________________________\n",
            "gru_7 (GRU)                  multiple                  123648    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  8212785   \n",
            "_________________________________________________________________\n",
            "bahdanau_attention_1 (Bahdan multiple                  33153     \n",
            "=================================================================\n",
            "Total params: 12,543,218\n",
            "Trainable params: 12,543,218\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYtpd7rXaUjo",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR7uqhJraUjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "#   print(type(mask))\n",
        "  loss_ *= mask\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFD-OP2iaUjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrWs6_TLaUjz",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        ">1. Pass *input* through *encoder* to get *encoder output*..\n",
        ">2. Then encoder output, encoder hidden state and the decoder input is passed to decoder.\n",
        ">3. Decoder returns *predictions* and *decoder hidden state*.\n",
        ">4. Decoder hidden state is then passed back to model.\n",
        ">5. Predictions are used to calculate loss.\n",
        ">6. Use *teacher forcing* (technique where the target word is passed as the next input to the decoder) for the next input to the decoder.\n",
        ">7. Calculate gradients and apply it to *optimizer* for backpropogation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN1p75IPaUj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)\n",
        "    # Teacher forcing\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))      \n",
        "  return batch_loss"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88es5CzUaUj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ca75853-7bed-4cb2-f445-1eff784496ab"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "    if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.5837\n",
            "Epoch 1 Batch 100 Loss 3.1380\n",
            "Epoch 1 Batch 200 Loss 2.9555\n",
            "Epoch 1 Batch 300 Loss 2.9792\n",
            "Epoch 1 Batch 400 Loss 3.0598\n",
            "Epoch 1 Batch 500 Loss 2.9903\n",
            "Epoch 1 Batch 600 Loss 2.8687\n",
            "Epoch 1 Batch 700 Loss 2.8128\n",
            "Epoch 1 Batch 800 Loss 2.8744\n",
            "Epoch 1 Batch 900 Loss 2.8753\n",
            "Epoch 1 Loss 2.9632\n",
            "Time taken for 1 epoch 390.5985233783722 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.7638\n",
            "Epoch 2 Batch 100 Loss 2.5666\n",
            "Epoch 2 Batch 200 Loss 2.6197\n",
            "Epoch 2 Batch 300 Loss 2.6345\n",
            "Epoch 2 Batch 400 Loss 2.6192\n",
            "Epoch 2 Batch 500 Loss 2.6831\n",
            "Epoch 2 Batch 600 Loss 2.5609\n",
            "Epoch 2 Batch 700 Loss 2.5410\n",
            "Epoch 2 Batch 800 Loss 2.5582\n",
            "Epoch 2 Batch 900 Loss 2.5931\n",
            "Epoch 2 Loss 2.5879\n",
            "Time taken for 1 epoch 348.2093560695648 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.3534\n",
            "Epoch 3 Batch 100 Loss 2.3866\n",
            "Epoch 3 Batch 200 Loss 2.5353\n",
            "Epoch 3 Batch 300 Loss 2.5281\n",
            "Epoch 3 Batch 400 Loss 2.3465\n",
            "Epoch 3 Batch 500 Loss 2.3883\n",
            "Epoch 3 Batch 600 Loss 2.4265\n",
            "Epoch 3 Batch 700 Loss 2.2899\n",
            "Epoch 3 Batch 800 Loss 2.3246\n",
            "Epoch 3 Batch 900 Loss 2.3420\n",
            "Epoch 3 Loss 2.3830\n",
            "Time taken for 1 epoch 345.75697207450867 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 2.0267\n",
            "Epoch 4 Batch 100 Loss 2.2462\n",
            "Epoch 4 Batch 200 Loss 2.1280\n",
            "Epoch 4 Batch 300 Loss 2.3032\n",
            "Epoch 4 Batch 400 Loss 2.2457\n",
            "Epoch 4 Batch 500 Loss 2.2599\n",
            "Epoch 4 Batch 600 Loss 2.1552\n",
            "Epoch 4 Batch 700 Loss 2.2610\n",
            "Epoch 4 Batch 800 Loss 2.0493\n",
            "Epoch 4 Batch 900 Loss 2.2442\n",
            "Epoch 4 Loss 2.2399\n",
            "Time taken for 1 epoch 346.5746910572052 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 2.1746\n",
            "Epoch 5 Batch 100 Loss 2.1102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-081d05cee36d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWBlcHKAaUj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence, encoder=encoder, decoder=decoder, inp_lang=inp_lang, targ_lang=targ_lang, max_length_inp=max_length_inp, max_length_targ=max_length_targ):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = pre_process_english_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                          maxlen=max_length_inp,\n",
        "                                                          padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "      predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                          dec_hidden,\n",
        "                                                          enc_out)\n",
        "\n",
        "      # storing the attention weights to plot later on\n",
        "      attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "      attention_plot[t] = attention_weights.numpy()\n",
        "      predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "      result += targ_lang.idx2word[predicted_id] + ' '\n",
        "\n",
        "      if targ_lang.idx2word[predicted_id] == '<end>':\n",
        "        return result, sentence, attention_plot\n",
        "\n",
        "      # the predicted ID is fed back into the model\n",
        "      dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5pnXKESA6bE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    \n",
        "    fontdict = {'fontsize': 14}\n",
        "    \n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYBJJN5FaUkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEUc35aVaUkJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8c9a48a-fb57-4109-8c34-2ca00e7294c3"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbb92e24358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVqGY-8UaUkN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b5f4032-254c-4648-e07e-a23b7f2e218b"
      },
      "source": [
        "translate(u'how much does this cost?')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> how much does this cost <end>\n",
            "Predicted translation: क्या इस प्रकार के लिए <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2381 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2311 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2360 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2346 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2352 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2375 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2354 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2319 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2381 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2311 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2360 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2346 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2352 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2375 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2354 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2319 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHbC86dPzH5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a3a4f1c-8511-4515-abb6-c20982ad51c2"
      },
      "source": [
        "translate(u'you are my friend.')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> you are my friend <end>\n",
            "Predicted translation: मैं तुम्हें कोई <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2350 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2376 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2306 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2340 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2369 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2381 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2375 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2379 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2312 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2350 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2376 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2306 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2340 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2369 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2381 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2375 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2379 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2312 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}